{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46198a85",
   "metadata": {},
   "source": [
    "# MultiQueryRetriever\n",
    "\n",
    "ê±°ë¦¬ ê¸°ë°˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ì€ ê³ ì°¨ì› ê³µê°„ì—ì„œì˜ ì¿¼ë¦¬ ì„ë² ë”©(í‘œí˜„)ê³¼ 'ê±°ë¦¬'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìœ ì‚¬í•œ ì„ë² ë”©ì„ ê°€ì§„ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¿¼ë¦¬ì˜ **ì„¸ë¶€ì ì¸ ì°¨ì´ë‚˜ ì„ë² ë”©ì´ ë°ì´í„°ì˜ ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ í¬ì°©í•˜ì§€ ëª»í•  ê²½ìš°, ê²€ìƒ‰ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜** ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ë‚˜ íŠœë‹ ì‘ì—…ì€ ë²ˆê±°ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, `MultiQueryRetriever` ëŠ” ì£¼ì–´ì§„ ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬ì— ëŒ€í•´ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” LLM(Language Learning Model)ì„ í™œìš©í•´ í”„ë¡¬í”„íŠ¸ íŠœë‹ ê³¼ì •ì„ ìë™í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°©ì‹ì€ ê°ê°ì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œ ì§‘í•©ì„ ê²€ìƒ‰í•˜ê³ , ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì•„ìš°ë¥´ëŠ” ê³ ìœ í•œ ë¬¸ì„œë“¤ì˜ í•©ì§‘í•©ì„ ì¶”ì¶œí•´, ì ì¬ì ìœ¼ë¡œ ê´€ë ¨ëœ ë” í° ë¬¸ì„œ ì§‘í•©ì„ ì–»ì„ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. \n",
    "\n",
    "ì—¬ëŸ¬ ê´€ì ì—ì„œ ë™ì¼í•œ ì§ˆë¬¸ì„ ìƒì„±í•¨ìœ¼ë¡œì¨, `MultiQueryRetriever` ëŠ” ê±°ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ì˜ ì œí•œì„ ì¼ì • ë¶€ë¶„ ê·¹ë³µí•˜ê³ , ë”ìš± í’ë¶€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee62e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce16f0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH10-Retriever\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH10-Retriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae75cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìƒ˜í”Œ ë²¡í„°DB êµ¬ì¶•\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "import requests\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# requestsì˜ ê¸°ë³¸ verify ì˜µì…˜ì„ Falseë¡œ ì„¤ì •\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "original_request = requests.Session.request\n",
    "\n",
    "def unsafe_request(self, *args, **kwargs):\n",
    "    kwargs['verify'] = False\n",
    "    return original_request(self, *args, **kwargs)\n",
    "\n",
    "requests.Session.request = unsafe_request\n",
    "\n",
    "# ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¡œë“œ\n",
    "loader = WebBaseLoader(\n",
    "    \"https://teddylee777.github.io/openai/openai-assistant-tutorial/\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# ì‚¬ìš© í›„ì—ëŠ” ë°˜ë“œì‹œ ì›ë˜ëŒ€ë¡œ ë³µêµ¬í•˜ì„¸ìš”!\n",
    "# requests.Session.request = original_request\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# ì„ë² ë”© ì •ì˜\n",
    "bedrock_embedding = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "# ë²¡í„°DB ìƒì„±\n",
    "db = FAISS.from_documents(docs, bedrock_embedding)\n",
    "\n",
    "# retriever ìƒì„±\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰\n",
    "query = \"OpenAI Assistant APIì˜ Functions ì‚¬ìš©ë²•ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê°œìˆ˜ ì¶œë ¥\n",
    "len(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d88fd7",
   "metadata": {},
   "source": [
    "ê²€ìƒ‰ëœ ê²°ê³¼ ì¤‘ 1ê°œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ea9548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²• - í…Œë””ë…¸íŠ¸\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to primary navigation\n",
      "Skip to content\n",
      "Skip to footer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          í…Œë””ë…¸íŠ¸\n",
      "          ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\n",
      "\n",
      "\n",
      "ê²€ìƒ‰\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬\n",
      "\n",
      "íƒœê·¸\n",
      "\n",
      "ì—°ë„\n",
      "\n",
      "ê°•ì˜\n",
      "\n",
      "ì–´ë°”ì›ƒë¯¸\n",
      "\n",
      "\n",
      "í† ê¸€ ë©”ë‰´\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "/\n",
      "\n",
      "Openai\n",
      "\n",
      "\n",
      "/\n",
      "[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ğŸ”¥ì•Œë¦¼ğŸ”¥\n",
      "\n",
      "    â‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - \n",
      "    êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\n",
      "\n",
      "    â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\n",
      "ë°”ë¡œê°€ê¸° ğŸ‘€\n",
      "\n",
      "    â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) \n",
      "    ë°”ë¡œê°€ê¸° ğŸ™Œ\n"
     ]
    }
   ],
   "source": [
    "# 1ë²ˆ ë¬¸ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(relevant_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3224e",
   "metadata": {},
   "source": [
    "## ì‚¬ìš©ë°©ë²•\n",
    "\n",
    "`MultiQueryRetriever` ì— ì‚¬ìš©í•  LLMì„ ì§€ì •í•˜ê³  ì§ˆì˜ ìƒì„±ì— ì‚¬ìš©í•˜ë©´, retrieverê°€ ë‚˜ë¨¸ì§€ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a5308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock ì„¤ì • ë° Util í•¨ìˆ˜ ì„¤ì •\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "import os\n",
    "from Util.stream_utils import print_stream_content, get_stream_content\n",
    "\n",
    "# ê°ì²´ ìƒì„±\n",
    "llm = ChatBedrockConverse(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    model=\"apac.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    region_name=\"ap-northeast-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1637815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(  # MultiQueryRetrieverë¥¼ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ retrieverì™€ ì–¸ì–´ ëª¨ë¸ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    retriever=db.as_retriever(),\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0b647",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” ë‹¤ì¤‘ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ê°„ ê³¼ì •ì„ ë””ë²„ê¹…í•˜ê¸° ìœ„í•˜ì—¬ ì‹¤í–‰í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € `\"langchain.retrievers.multi_query\"` ë¡œê±°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. \n",
    "\n",
    "ì´ëŠ” `logging.getLogger()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ë©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ, ì´ ë¡œê±°ì˜ ë¡œê·¸ ë ˆë²¨ì„ `INFO`ë¡œ ì„¤ì •í•˜ì—¬, `INFO` ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ ë©”ì‹œì§€ë§Œ ì¶œë ¥ë˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901d1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¿¼ë¦¬ì— ëŒ€í•œ ë¡œê¹… ì„¤ì •\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda8ebb",
   "metadata": {},
   "source": [
    "ì´ ì½”ë“œëŠ” `retriever_from_llm` ê°ì²´ì˜ `invoke` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ `question`ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. \n",
    "\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì€ `unique_docs`ë¼ëŠ” ë³€ìˆ˜ì— ì €ì¥ë˜ë©°, ì´ ë³€ìˆ˜ì˜ ê¸¸ì´ë¥¼ í™•ì¸í•¨ìœ¼ë¡œì¨ ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œì˜ ì´ ê°œìˆ˜ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì°¾ì•„ë‚´ê³  ê·¸ ì–‘ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e305f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant APIì—ì„œ Functions ê¸°ëŠ¥ì„ ì–´ë–»ê²Œ í™œìš©í•˜ë‚˜ìš”?', 'OpenAI Assistant APIì˜ í•¨ìˆ˜ í˜¸ì¶œ ë°©ë²•ê³¼ êµ¬í˜„ ì˜ˆì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'Assistant API Functionsì˜ ì •ì˜, íŒŒë¼ë¯¸í„° ì„¤ì •, ì‹¤í–‰ ê³¼ì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.', 'OpenAI Assistantì—ì„œ ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ê³  ì—°ë™í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?', 'Assistant APIì˜ Function calling ê¸°ëŠ¥ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: 9\n",
      "===============\n",
      "OpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval, Functions ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ì´ì™€ ë”ë¶ˆì–´ íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ëŠ” ë‚´ìš©ê³¼ ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ì œì¶œí•˜ëŠ” ë‚´ìš©ë„ íŠœí† ë¦¬ì–¼ ë§ë¯¸ì— í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "\n",
      "ì£¼ìš”ë‚´ìš©\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "question = \"OpenAI Assistant APIì˜ Functions ì‚¬ìš©ë²•ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "# ë¬¸ì„œ ê²€ìƒ‰\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ê³ ìœ í•œ ë¬¸ì„œì˜ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"===============\\nê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81695892",
   "metadata": {},
   "source": [
    "## LCEL Chain í™œìš©í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "- ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì •ì˜í•˜ê³ , ì •ì˜í•œ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ Chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- Chain ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì…ë ¥ ë°›ìœ¼ë©´ (ì•„ë˜ì˜ ì˜ˆì œì—ì„œëŠ”) 5ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•œ ë’¤ `\"\\n\"` êµ¬ë¶„ìë¡œ êµ¬ë¶„í•˜ì—¬ ìƒì„±ëœ 5ê°œ ì§ˆë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab98687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI Assistant APIì—ì„œ Functions ê¸°ëŠ¥ì„ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?\\n\\nAssistant APIì˜ í•¨ìˆ˜ í˜¸ì¶œ(Function Calling) êµ¬í˜„ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\\n\\nOpenAI Assistantì—ì„œ ì™¸ë¶€ í•¨ìˆ˜ë¥¼ ì—°ë™í•˜ëŠ” ë°©ë²•ì´ ê¶ê¸ˆí•©ë‹ˆë‹¤.\\n\\nAssistant API Functionsì˜ ì •ì˜ ë° ì‹¤í–‰ ê³¼ì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\\n\\nOpenAI Assistant APIë¡œ ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê³  í˜¸ì¶œí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤.(5ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language model assistant. \n",
    "Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. \n",
    "By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "Your response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n",
    "\n",
    "#ORIGINAL QUESTION: \n",
    "{question}\n",
    "\n",
    "#Answer in Korean:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# LLMChainì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "custom_multiquery_chain = (\n",
    "    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "question = \"OpenAI Assistant APIì˜ Functions ì‚¬ìš©ë²•ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ì„ ì‹¤í–‰í•˜ì—¬ ìƒì„±ëœ ë‹¤ì¤‘ ì¿¼ë¦¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "multi_queries = custom_multiquery_chain.invoke(question)\n",
    "# ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.(5ê°œ ì§ˆë¬¸ ìƒì„±)\n",
    "multi_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6403eb",
   "metadata": {},
   "source": [
    "ì´ì „ì— ìƒì„±í•œ Chainì„ `MultiQueryRetriever` ì— ì „ë‹¬í•˜ì—¬ retrieve í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3cac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=custom_multiquery_chain, retriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086076bb",
   "metadata": {},
   "source": [
    "`MultiQueryRetriever`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eaffe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant APIì—ì„œ Functions ê¸°ëŠ¥ì„ ì–´ë–»ê²Œ í™œìš©í•˜ë‚˜ìš”?', 'OpenAI Assistant APIì˜ í•¨ìˆ˜ í˜¸ì¶œ ë°©ë²•ê³¼ êµ¬í˜„ ì˜ˆì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'Assistant API Functionsì˜ ì •ì˜, íŒŒë¼ë¯¸í„° ì„¤ì •, ì‹¤í–‰ ê³¼ì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.', 'OpenAI Assistantì—ì„œ ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê³  ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?', 'Assistant APIì˜ Function calling ê¸°ëŠ¥ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: 9\n",
      "===============\n",
      "OpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval, Functions ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ì´ì™€ ë”ë¶ˆì–´ íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ëŠ” ë‚´ìš©ê³¼ ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ì œì¶œí•˜ëŠ” ë‚´ìš©ë„ íŠœí† ë¦¬ì–¼ ë§ë¯¸ì— í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "\n",
      "ì£¼ìš”ë‚´ìš©\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ê³ ìœ í•œ ë¬¸ì„œì˜ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"===============\\nê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(relevant_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
