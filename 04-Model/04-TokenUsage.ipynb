{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 사용량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock 설정 및 Util 함수 설정\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "import os\n",
    "from Util.stream_utils import print_stream_content, get_stream_content\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatBedrockConverse(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    model=\"apac.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    region_name=\"ap-northeast-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH04-Models\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH04-Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 호출에 대한 토큰 사용량을 추적하는 방법에 대해 설명합니다.\n",
    "\n",
    "이 기능은 현재 OpenAI API 에만 구현되어 있습니다.\n",
    "\n",
    "먼저 단일 Chat 모델 호출에 대한 토큰 사용량을 추적하는 매우 간단한 예를 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bedrock 토큰 사용량 정보 ===\n",
      "응답 내용: 대한민국의 수도는 서울입니다.\n",
      "\n",
      "입력 토큰 수: 22\n",
      "출력 토큰 수: 20\n",
      "총 토큰 수: 42\n",
      "\n",
      "=== 응답 메타데이터 ===\n",
      "Stop Reason: end_turn\n",
      "지연시간: [1013] ms\n"
     ]
    }
   ],
   "source": [
    "# Bedrock에서 토큰 사용량 추적 예시\n",
    "message = \"대한민국의 수도는 어디야?\"\n",
    "\n",
    "# 모델 호출\n",
    "response = llm.invoke(message)\n",
    "\n",
    "print(\"=== Bedrock 토큰 사용량 정보 ===\")\n",
    "print(f\"응답 내용: {response.content}\")\n",
    "print()\n",
    "\n",
    "# usage_metadata에서 토큰 정보 확인\n",
    "if hasattr(response, \"usage_metadata\") and response.usage_metadata:\n",
    "    usage_info = response.usage_metadata\n",
    "    print(f\"입력 토큰 수: {usage_info.get('input_tokens', 'N/A')}\")\n",
    "    print(f\"출력 토큰 수: {usage_info.get('output_tokens', 'N/A')}\")\n",
    "    print(f\"총 토큰 수: {usage_info.get('total_tokens', 'N/A')}\")\n",
    "else:\n",
    "    print(\"토큰 사용량 정보를 사용할 수 없습니다.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# response_metadata에서 추가 정보 확인\n",
    "if hasattr(response, \"response_metadata\") and response.response_metadata:\n",
    "    print(\"=== 응답 메타데이터 ===\")\n",
    "    metadata = response.response_metadata\n",
    "    print(f\"Stop Reason: {metadata.get('stopReason', 'N/A')}\")\n",
    "\n",
    "    # 메트릭 정보 (지연시간 등)\n",
    "    if \"metrics\" in metadata:\n",
    "        metrics = metadata[\"metrics\"]\n",
    "        print(f\"지연시간: {metrics.get('latencyMs', 'N/A')} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델을 불러옵니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`with get_openai_callback()` 구문안에서 실행되는 모든 토큰 사용량/요금이 추적됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback을 사용하여 추적합니다.\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"대한민국의 수도는 어디야?\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback을 사용하여 추적합니다.\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"대한민국의 수도는 어디야?\")\n",
    "    result = llm.invoke(\"대한민국의 수도는 어디야?\")\n",
    "    print(f\"총 사용된 토큰수: \\t\\t{cb.total_tokens}\")\n",
    "    print(f\"프롬프트에 사용된 토큰수: \\t{cb.prompt_tokens}\")\n",
    "    print(f\"답변에 사용된 토큰수: \\t{cb.completion_tokens}\")\n",
    "    print(f\"호출에 청구된 금액(USD): \\t${cb.total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
